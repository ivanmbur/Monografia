This chapter shows how both classical and quantum mechanics are probability theories. This is not intended as an aximatization of these theories. Indeed the reader is assumed to be comfortable with these physical theories as well as the basic mathematical concepts of measure theory and functional analysis.

\section{Classical Mechanics}

The setting of classical mechanics is usually a locally compact Hausdorff space $X$. We consider the states of maximal knowledge (or pure states) to be the elements of $X$. Likewise, observables take the form of functions on $X$. We call the points of $X$ states of maximal knowledge because we interpret $f(p)$ as the value of the obsevable $f$ in the state $p\in X$. Moreover, given that in principle we could make the value of an observable as precise as we want by improving our knowledge of the state, observables are elements of the set of continuous functions $C(X)$\footnote{It doesn't matter whether we consider them real or complex at this stage.}. Nonetheless the purpose of statistical mechanics is to treat systems in which total knowledge of a state is not practically posible. Instead we consider a probability measure\footnote{Along with a $\sigma$-algebra which we won't mention explicitely to keep the notation simple but should always be kept in mind.} which assigns to every measurable subset of $X$ a probability of the system's state being in it. We may define the expected value of an observable $f\in C(X)$ through a probability measure $P$ by 
\begin{equation}
\langle f \rangle_P = \int fdP.
\end{equation}  
Notice that an element $p\in X$ can also be though as a probability measure by using the Dirac measure $\delta_p$ which assigns $1$ to a set if it contains $p$ and $0$ otherwise. Indeed for every element $p \in X$ and observable $f \in C(X)$ we have $\langle f \rangle_{\delta_p} = f(p)$. This motivates us to broaden the definition of states to the probability measures on $X$. We will call Dirac measures (or equivalently the points in $X$) pure states.

This definition of state proves to be very helpful for the discussion of ensembles. Whenever the description of the state of a system as a pure state is not feasible, we may consider the set of outcomes $Y$ of measurements we may perform on the system. Every element of $Y$ gives us information of the system in the form of a finite measure. We may define an ensemble as the mapping from $Y$ into the set of finite measures on $X$. Through normalization of finite measures every ensemble yields a mapping from $Y$ into the set of states and we define the accesible (pure) states of an element $y\in Y$ to be the support of the corresponding state. Although the construction of an ensemble is in general a difficult task, for systems in statistical equilibrium\footnote{These are systems whose state does not change in time. We refer to the equilibrium as statistical because it may be that the pure state of the system is changing in time but noticing these changes is not feasible for us.} there are many standard procedures. In the case of these type of systems we define the partition function $Z:Y\to \mathbb{R}^+_0$ by assigning to every element $y$ the measure of $X$ given by the ensemble evaluated at $y$.

\begin{example}
In many physical systems the space of pure states has a natural notion of size which we may represent by giving it the structure of a measure space $(X,\mathcal{A},\mu)$ where $\mathcal{A}$ contains the Borel $\sigma$-algebra\footnote{Usually we take a countable set with the counting measure but another example would be a phase space with the Liouville measure. In the latter, it is common that $H^{-1}(y)$ is a set of measure zero so we actually have to take $X=H^{-1}(y)$ with the appropiate induced measure.} . We may consider $Y = \mathbb{R}$ to be the set of energy outcomes. If $H:X\rightarrow \mathbb{R}$ is a measurable function taking the interpretation of energy we define the microcanonical ensemble to be the mapping $y\mapsto \mu_y$ where $\mu_y(\Sigma) = \mu(\Sigma\cap H^{-1}(y))$ for all measurable $\Sigma$. The set $H^{-1}(y)$ is the set of accesible states and $\mu_y(\Sigma)$ measures the amount of pure states in $\Sigma$ which are accesible. Notice that the normalization of $\mu_y$ yields a state $P_y$ which assigns a uniform probability measure to $X$. This is called the equal a priori probabilities postulate. In this ensemble the partition function $Z(y) = \mu_y(X) = \mu(H^{-1}(y))$ is just the amount of accesible states. This ensemble is usually used to describe systems with constant energy and a fixed number of particles.
\end{example}

\begin{example}
Consider again a measure space $(X,\mathcal{A},\mu)$ but let $Y=\mathbb{R}^+$ be the set of inverse temperatures of the system. If we have an energy function $H:X\rightarrow \mathbb{R}$ such that $x\rightarrow \exp(-y H(x))$ is integrable for all $y \in Y$ the canonical ensemble assigns to every inverse temperature $y$ a finite measure $\mu_y$ by
\begin{equation}
\mu_y(\Sigma)=\int_\Sigma e^{-y H(x)}d\mu(x)
\end{equation}
for all measurable sets $\Sigma$. This ensemble is usually used to describe systems with a fixed number of particles in thermal equilibrium with a heat bath. Note that we could add to the description of the system the heat bath and we would be able to in principle use the microcanonical ensemble. The difficulty lies in that generally the counting of accesible states is more difficult than the application of the canonical ensemble.
\end{example}

Note that both of the ensembles discussed have images consisting of absolutely continuous measures $\mu_y$ with respect to the notion of size $\mu$. The same is true for the induced states $P_y$. Moreover the Lebesgue-Radon-Nikod√Ωm derivative exits and we define the entropy of the ensemble in the state $P_y$ by\footnote{In general if we start from a decomposible $(X,\mathcal{A},\mu)$ and have an ensemble which yields absolutely continuous measures with respect to $\mu$ we can define entropy in this fashion. In particular, if $\mu$ comes from the Daniel extension of a positive linear functional the space is decomposible.}
\begin{equation}
S(P_y)=-\int_{supp(P_y)} \log\left(\frac{dP_y}{d\mu}\right)\frac{dP_y}{d\mu}d\mu.
\end{equation}
One can check that in the microcanonical ensemble 
\begin{equation}
\frac{dP_y}{d\mu}(x)=\frac{\chi_{H^{-1}(y)}(x)}{Z(y)}
\end{equation}
and in the canonical ensemble 
\begin{equation}
\frac{dP_y}{d\mu}(x)=\frac{\exp(-yH(x))}{Z(y)}. 
\end{equation}
In the case we have a state of maximal knowledge $\delta_p$ we may collapse $X$ to $(\{p\},\{\{p\},\emptyset\},\delta_p)$ and define an ensemble $y\mapsto \delta_p$. Such an ensemble has zero entropy.

\section{Quantum Mechanics}\label{sec:QM}

The setting of quantum mechanics is a separable Hilbert space $\mathcal{H}$. In this case the states are the non-negative self-adjoint operators of unit trace on $\mathcal{H}$ (called density operators) and observables take the form of self-adjoint operators on $\mathcal{H}$. The possible outcomes of an observable $A$ are the elements of its spectrum and, if $P_A$ is the unique projection-valued measure such that $A=\int id_\mathcal{H}dP_A$ given by the spectral theorem, we have that the probability of the measurement of the observable $A$ yielding a value in the measurable subset $E\subseteq\mathbb{R}$ in the state $\rho$ is $tr(P_A(E)\rho)$. One can check that given this way of measuring probabilities we have that the expected value of an observable $A$ in the state $\rho$ is
\begin{equation}
\langle A\rangle_\rho = tr(A\rho).
\end{equation}
Moreover we define the entropy of a state $\rho$ to be
\begin{equation}
S(\rho)=-tr(\log(\rho)\rho).
\end{equation}
Inspired by the classical case we define a pure state $\rho_\psi$ to be orthogonal projection on the span of $\psi$ for $\psi\in\mathcal{H}$ of unit norm. Although such a state has null entropy as in the classical case
\begin{equation}
S(\rho_\psi)=-tr(\log(\rho_\psi)\rho_\psi)=-\langle\psi,\log(1)\psi\rangle = 0,
\end{equation} 
we can't in general associate to an observable $A$ a definite outcome unless $\psi$ is an eigenvector of $A$ corresponding to an eigenvalue $\lambda$ where we have 
\begin{equation}
tr(P_A(\{\lambda\})\rho_\psi)=\langle\psi,P_A(\{\lambda\})\psi\rangle=\langle\psi,\psi\rangle=\|\psi\|^2=1. 
\end{equation}
Notice that we haven't inspired the definition of a state like we did in the classical case. The connection between states and probability is given through the study of quantum logic in the next chapter.